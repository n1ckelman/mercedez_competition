{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import f_regression, SelectKBest\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.pyll.stochastic import sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('train.csv', index_col='ID')\n",
    "x_test = pd.read_csv('test.csv', index_col='ID')\n",
    "y_train = x_train['y']\n",
    "x_train.drop('y', axis=1, inplace=True)\n",
    "\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_to_int(df, col_name):\n",
    "    if df[col_name].dtype != 'int64':\n",
    "        le.fit(df[col_name].values)\n",
    "        df[col_name] = le.transform(df[col_name])\n",
    "\n",
    "for col_name in x_train.columns:\n",
    "    str_to_int(x_train, col_name)\n",
    "    str_to_int(x_test, col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection and generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krybkin/anaconda/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:279: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= row_norms(X.T)\n",
      "/Users/krybkin/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/krybkin/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/krybkin/anaconda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "selector = SelectKBest(k=75, score_func=f_regression).fit(x_train, y_train)\n",
    "x_train_new = selector.transform(x_train)\n",
    "x_test_new = selector.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krybkin/anaconda/lib/python3.6/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA, FastICA\n",
    "n_comp = 10\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=42)\n",
    "pca2_results_train = pca.fit_transform(x_train)\n",
    "pca2_results_test = pca.transform(x_test)\n",
    "\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=42)\n",
    "ica2_results_train = ica.fit_transform(x_train)\n",
    "ica2_results_test = ica.transform(x_test)\n",
    "\n",
    "x_train_new = pd.DataFrame(x_train_new)\n",
    "x_test_new = pd.DataFrame(x_test_new)\n",
    "\n",
    "# Append decomposition components to datasets\n",
    "for i in range(1, n_comp+1):\n",
    "    x_train_new['pca_' + str(i)] = pca2_results_train[:,i-1]\n",
    "    x_test_new['pca_' + str(i)] = pca2_results_test[:, i-1]\n",
    "    \n",
    "    x_train_new['ica_' + str(i)] = ica2_results_train[:,i-1]\n",
    "    x_test_new['ica_' + str(i)] = ica2_results_test[:, i-1]\n",
    "    \n",
    "y_mean = np.mean(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Append decomposition components to datasets\n",
    "for i in range(1, n_comp+1):\n",
    "    x_train_new['pca_' + str(i)] = pca2_results_train[:,i-1]\n",
    "    x_test_new['pca_' + str(i)] = pca2_results_test[:, i-1]\n",
    "    \n",
    "    x_train_new['ica_' + str(i)] = ica2_results_train[:,i-1]\n",
    "    x_test_new['ica_' + str(i)] = ica2_results_test[:, i-1]\n",
    "    \n",
    "y_mean = np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(x_train_new, y_train, random_state=42, train_size=.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:12.5191\ttest-rmse:12.5179\n",
      "[50]\ttrain-rmse:8.99811\ttest-rmse:9.00387\n",
      "[100]\ttrain-rmse:8.43949\ttest-rmse:8.47981\n",
      "[150]\ttrain-rmse:8.2447\ttest-rmse:8.39429\n",
      "[200]\ttrain-rmse:8.09566\ttest-rmse:8.372\n",
      "[250]\ttrain-rmse:7.9588\ttest-rmse:8.36543\n",
      "[300]\ttrain-rmse:7.85318\ttest-rmse:8.36954\n",
      "[350]\ttrain-rmse:7.75878\ttest-rmse:8.37366\n",
      "251\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_params = {\n",
    "    'n_trees': 374, \n",
    "    'eta': 0.025,\n",
    "    'gamma': 0.55,\n",
    "    'max_depth': 2,\n",
    "    'subsample': 0.8,\n",
    "    'min_child_weight': 2,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'reg:linear',\n",
    "    'nthread': 6,\n",
    "    'eval_metric': 'rmse',\n",
    "    'base_score': y_mean, # base prediction = mean(target)\n",
    "    'silent': 1\n",
    "}\n",
    "# xgb_params = {'colsample_bytree': 0.65, 'eta': 0.30000000000000004, 'eval_metric': 'rmse', 'gamma': 0.9500000000000001, 'max_depth': 8, 'min_child_weight': 1.0, 'n_estimators': 110.0, 'nthread': 6, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.9}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train_new, y_train)\n",
    "dtest = xgb.DMatrix(x_test_new)\n",
    "\n",
    "# xgboost, cross-validation\n",
    "cv_result = xgb.cv(xgb_params, \n",
    "                   dtrain, \n",
    "                   num_boost_round=1500,\n",
    "                   early_stopping_rounds=150,\n",
    "                   verbose_eval=50, \n",
    "                   show_stdv=False\n",
    "                  )\n",
    "\n",
    "num_boost_rounds = len(cv_result)\n",
    "print(num_boost_rounds)\n",
    "\n",
    "# train model\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    print(\"Training with params : \")\n",
    "    print(params)\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_val, label=y_val)\n",
    "    # watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    model = xgb.train(params, dtrain, num_round)\n",
    "    predictions = model.predict(dvalid)\n",
    "    score = r2_score(y_val, predictions)\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    space = {\n",
    "             'n_estimators' : hp.quniform('n_estimators', 100, 1000, 1),\n",
    "             'eta' : hp.quniform('eta', 0.0001, 0.5, 0.025),\n",
    "             'max_depth' : sample(scope.int(hp.quniform('max_depth', 0, 10, 1))),\n",
    "             'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n",
    "             'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "             'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "             'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "             'eval_metric': 'rmse',\n",
    "             'objective': 'reg:linear',\n",
    "             'nthread' : 8,\n",
    "             'silent' : 1\n",
    "             }\n",
    "\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n",
    "\n",
    "    print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "optimize(trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(dtest)\n",
    "output = pd.DataFrame({'id': x_test.index, 'y': y_pred})\n",
    "output.to_csv('xgboost-depth{}-pca-ica.csv'.format(xgb_params['max_depth']), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
